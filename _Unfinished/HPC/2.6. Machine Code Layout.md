计算机工程师喜欢在心里把 [CPU 的流水线](https://en.algorithmica.org/hpc/pipelining)分成两部分：前端，指令从内存中取出并解码；后端，指令被调度并最终执行。通常情况下，性能受到执行阶段的瓶颈，因此，本书中的大部分工作将用于围绕后端进行优化。

但有时，当前端没有足够快地将指令提供给后端以使其饱和时，也会发生相反的情况。发生这种情况的原因有很多，它们都与机器代码在内存中的布局有关，并因为各种原因影响着性能。例如删除未使用的代码、交换分支，甚至改变函数声明的顺序，都可能导致性能变化。

# CPU 前端 - *CPU Front-End*

在机器码被转换成指令之前，CPU 需要知道程序员想要什么，它首先需要经历我们感兴趣的两个重要阶段：获取和解码。

在**获取**阶段，CPU 只是从主存储器中加载一个固定大小的字节块，其中包含一定数量指令的二进制编码。该块大小在 x86 上通常为 32 字节，在其他机器上可能有所不同。一个重要的细微差别是，这个块必须[对齐](https://en.algorithmica.org/hpc/cpu-cache/cache-lines)：块的地址必须是其大小的倍数（在我们的例子中是 32B）。

接下来是**解码**阶段：CPU 查看这个字节块，丢弃指令指针之前的所有内容，并将其余部分拆分为指令。机器指令使用可变字节数进行编码：一些简单而非常常见的指令，如 `incrax`，需要一个字节，而一些带有编码常量和行为修改前缀的模糊指令可能需要多达 15 个字节。因此，从一个 32 字节的块中可以解码出的指令数量是不固定的，但不能超过某个与机器相关的限制，这称为解码宽度。在我的 CPU （Zen 2）上，解码宽度为 4，这意味着在每个周期中，最多可以解码 4 条指令并传递到下一阶段。

这些阶段以流水线的方式工作：如果 CPU 可以告知（或预测）下一个指令块，那么提取阶段不会等待当前块中的最后一条指令被解码完毕，而是立即加载下一条指令。

# 机器码对齐 - *Code Alignment*

在其他条件相同的情况下，编译器通常更喜欢机器代码较短的指令，因为这样可以在一个 32B 的块中容纳更多的指令，也因为它减少了二进制文件的大小。但有时相反的情况更可取，因为获取的指令块必须对齐。

假设你需要执行一个指令序列，它从 32B 对齐（即 32B 的整数倍大小）块的最后一个字节开始。你可能能够在没有额外延迟的情况下执行第一个指令，但是对于后续的指令，你必须等待一个额外的周期来获取指令。如果代码块在 32B 的边界上对齐，那么最多可以解码 4 条指令，然后并发执行（除非它们特别长或相互依赖）。

考虑到这一点，编译器通常会进行看似有害的优化：它们有时更喜欢具有较长机器码的指令，甚至会插入不执行任何操作的虚拟指令[^1]，以便将跳转位置对齐到合适的 2 次幂边界上。

在 GCC 中，你可以使用 `-falign-labels=n` 标志来指定特定的对齐策略，如果你希望更有选择性，可以将 `-labels` [替换](https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html)为 `-function`、`-loops` 或 `-jump`。在 `-O2` 和 `-O3` 级别的优化中，默认情况下会启用它但不具体设置特定的对齐方式，在这种情况下，它使用（通常是合理的）与机器相关的默认值。

# 指令缓存 - *Instruction Cache*

指令的存储和获取基本上使用与数据相同的[内存系统](https://en.algorithmica.org/hpc/cpu-cache)，除了可能用单独的*指令缓存*替换较低层级的缓存（你当然不会希望随机读取的数据把处理这些数据的指令踢出缓存）。

指令缓存在以下两种情况下至关重要：

+ 不知道接下来要执行什么指令，但需要以[低延迟](https://en.algorithmica.org/hpc/cpu-cache/latency)获取下一个块
+ 正在执行一长串冗长但处理速度较快的指令，并且需要[高带宽](https://en.algorithmica.org/hpc/cpu-cache/bandwidth)。

因此，存储系统可能成为具有大量机器代码的程序的瓶颈。这种考虑限制了我们前面讨论的优化技术的适用性。

+ [内联函数](https://en.algorithmica.org/hpc/architecture/functions)并不总是最佳的，因为它减少了代码共享并增加了二进制大小，需要更多的指令缓存。
+ [循环展开](https://en.algorithmica.org/hpc/architecture/loops)只在一定程度上是有益的，即使在编译期间迭代的次数是已知的：在某些时候，CPU 必须从主存中获取指令和数据，在这种情况下，它就可能受到内存带宽的瓶颈。
+ 大的[对齐值](https://en.algorithmica.org/hpc/architecture/layout/#code-alignment)会增加二进制大小，同样需要更多的指令缓存。与丢失缓存并等待指令从主存中取出相比，在读取上多花一个周期是一个很小的损失。

另一个方面，将经常使用的指令序列放在相同的[缓存行](https://en.algorithmica.org/hpc/cpu-cache/cache-lines)和[内存页](https://en.algorithmica.org/hpc/cpu-cache/paging)上可以提高[缓存局部性](https://en.algorithmica.org/hpc/external-memory/locality)。为了提高指令缓存利用率，应该将热代码与热代码、冷代码与冷代码分组，并尽可能删除死代码（未使用的代码）。如果你想进一步探索这个想法，请查看 Facebook 的[二进制优化和布局工具](https://engineering.fb.com/2018/06/19/data-infrastructure/accelerate-large-scale-applications-with-bolt/)，它最近被[合并](https://github.com/llvm/llvm-project/commit/4c106cfdf7cf7eec861ad3983a3dd9a9e8f3a8ae)到 LLVM 中。

# 非平等分支 - *Unequal Branches*

假设由于某种原因，你需要一个辅助函数来计算整数间隔的长度。它接受两个参数，`x` 和 `y`，不过出于方便，没有规定这两个数谁必须更大。用 C 语言表示如下：

```C
int length(int x, int y) {
    if (x > y)
        return x - y;
    else
        return y - x;
}
```

在 x86 汇编中，有很多不同的实现方式，不同的方式会不同程度地影响性能。让我们从尝试将此代码直接映射到汇编开始：

```asm
length:
    cmp  edi, esi
    jle  less
    ; x > y
    sub  edi, esi
    mov  eax, edi
done:
    ret
less:
    ; x <= y
    sub  esi, edi
    mov  eax, esi
    jmp  done
```

虽然最初的 C 代码看起来非常对称，但汇编版本并非如此。

这导致了一个有趣的奇怪现象，一个分支的执行速度比另一个分支要快一些：如果 `x > y`，那么 CPU 可以只执行 `cmp` 和 `ret` 间的 5 条指令，如果函数是对齐的，那么这些指令都将一次取出；而在 `x <= y` 的情况下，则需要进行两次跳转。

假设 `x > y` 的情况可能不太合理（为什么会有人计算反向间隔的长度？），更像是一个通常不会发生的异常情况。我们可以检测到这种情况，简单地交换 `x` 和 `y`：

```C
int length(int x, int y) {
    if (x > y)
        swap(x, y);
    return y - x;
}
```

汇编如下，它通常用于 `if-without-else` 模式：

```asm
length:
    cmp  edi, esi
    jle  normal     ; if x <= y, no swap is needed, and we can skip the xchg
    xchg edi, esi
normal:
    sub  esi, edi
    mov  eax, esi
    ret
```

指令的总长度现在从 8 缩短为 6。但是对于我们假设的情况，它仍然没有完全优化：如果我们假设 `x > y` 永远不会发生，那么我们加载永远不会执行的 `xchg edi, esi` 指令就是一种浪费。我们可以通过将它移到正常的执行路径之外来解决这个问题：

```asm
length:
    cmp  edi, esi
    jg   swap
normal:
    sub  esi, edi
    mov  eax, esi
    ret
swap:
    xchg edi, esi
    jmp normal
```

在一般情况下处理异常情况时，这种技术非常方便。在高级代码表示中，你可以向编译器[提示](https://en.algorithmica.org/hpc/compilation/situational)某个分支比另一个分支更有可能发生：

```C
int length(int x, int y) {
    if (x > y) [[unlikely]]
        swap(x, y);
    return y - x;
}
```

这种优化只有在明确知道很少使用某一条分支时才有用。如果情况并非如此，那么可能有其他比代码布局更重要的[影响因素](https://en.algorithmica.org/hpc/pipelining/hazards)，迫使编译器完全避免任何分支——在这个例子里是通过特殊的“条件移动”指令代替分支，它大致对应于三元表达式 `(x > y ? y - x: x - y)` 或调用 `abs(x - y)`。

```asm
length:
    mov   edx, edi
    mov   eax, esi
    sub   edx, esi
    sub   eax, edi
    cmp   edi, esi
    cmovg eax, edx  ; "mov if edi > esi"
    ret
```

消除分支是一个重要的主题，我们将在[下一章的大部分时间](https://en.algorithmica.org/hpc/pipelining/branching)里更详细地讨论它。


[^1]: 这样的指令被称为 no-op 指令或 NOP 指令。在 x86 上，什么都不做的"官方做法"是 `xchg rax, rax` （与自身交换寄存器），CPU 会识别它，并且不花费额外的周期来执行它，除了解码阶段。`nop` 速记等价于上述指令的机器码。