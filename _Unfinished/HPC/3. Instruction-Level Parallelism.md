当程序员听到并行这个词时，他们大多想到的是多核并行，即显式地将计算任务拆分为独立的线程，这些线程一起工作以解决一个共同的问题。

这种类型的并行性主要是为了减少*延迟*和实现*可伸缩性*，而不是为了提高*效率*。你可以用并行算法解决十倍大的问题，但它至少需要十倍的计算资源。尽管并行硬件[越来越多](https://en.algorithmica.org/hpc/complexity/hardware)，并行算法设计也越来越重要，但现在，我们将限制自己只考虑单个 CPU 核心。

但是仍有其他类型的并行，它们存在于 CPU 核心中，你可以不加代价地使用。

# 指令流水线 - *Instruction Pipelining*

要执行任何指令，处理器首先需要做大量的准备工作，其中包括：

+ **获取** 内存中的一段机器码，
+ **解码** 它并分解成指令，
+ **执行** 这些指令，其中某些指令可能涉及内存操作，
+ **写入** 结果到寄存器。

整个操作序列很长。即使是像 `add` 那样把两个寄存器的值相加的简单事务，也需要花费大约 15-20 个 CPU 周期。为了隐藏延迟，现代 CPU 采用了*流水线*的技术：在一个指令通过第一阶段后，它们立即开始处理下一个指令，而不必等待前一个指令完全完成。

![[pipeline.png]]

流水线并没有减少实际的延迟，不过从功能上看，它似乎只由执行和内存阶段组成。你仍然需要花费这 15-20 个周期，但你只需要在找到要执行的指令序列后执行一次。

考虑到这一点，硬件制造商更喜欢使用*平均指令周期数*（*CPI*）而不是“平均指令延迟”作为 CPU 设计的主要性能指标。如果我们只考虑有用的指令，这也是算法设计的一个[很好的指标](https://en.algorithmica.org/hpc/profiling/benchmarking)。

一个完美的流水线处理器的 CPI 应该趋向于 1，但如果我们通过复制流水线的每个阶段使其更宽，那么它实际上可以更低，这样一次可以处理多个指令。因为缓存和大部分 ALU 可以共享，所以这比添加一个完全独立的核心要便宜。这种能够在一个周期内执行多条指令的体系结构被称为*超标量*，大多数现代 CPU 都是如此。

只有当指令流包含可以单独处理的逻辑独立操作组时，才能利用超标量处理。指令并不总是以方便处理的顺序到达，因此，在可能的情况下，现代 CPU 可以不按顺序执行它们，以提高总体利用率并最大限度地减少管道停顿。这个魔法是如何工作的是一个更高级的讨论主题，但是现在，你可以假设 CPU 维护一个待处理指令的缓冲区，并在计算出操作数的值并且有可用的执行单元时立即执行这些指令。

# 一个教育系统的类比 - *An Education Analogy*

想想我们的教育系统是如何运作的：

1. 专题报告是给一群学生而不是给一个人教授的，因为同时向每个人传播同样的东西更有效率。
2. 招收的学生被分成由不同老师领导的小组；作业和其他课程材料在小组之间共享。
3. 每年都给新入学的学生教授同样的课程，这样老师们就会保持忙碌。

这些创新极大地提高了整个系统的吞吐量，并且延迟（相当于特定学生的毕业时间）保持不变（可能会增加一点，因为个性化辅导通常更有效率）。

你可以在现代 CPU 中找到许多类似之处：

1. CPU 使用 [SIMD 并行](https://en.algorithmica.org/hpc/simd)在不同数据（由 16、32 或 64 字节组成）的块上执行相同的操作。
2. 有多个执行单元可以同时处理这些指令，同时共享其他 CPU 设施（通常为 2-4 个执行单元）。
3. 指令以流水线方式处理（节省的周期数与幼儿园到博士之间的年数大致相同）。

除此之外，其他几个方面也很匹配：

+ 随着时间的推移，执行路径变得越来越分散，需要不同的执行单元。
+ 一些指令可能由于各种原因而被搁置。
+ 有些指令被推测（进而提前执行），但随后被丢弃。
+ 有些指令可能被分割成几个不同的微操作，这些微操作可以独立进行。

在流水线和超标量处理器上进行编程有其自身的挑战，我们将在本章中讨论。
